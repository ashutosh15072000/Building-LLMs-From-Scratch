{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10d41bf3",
   "metadata": {},
   "source": [
    "## Step 1: Writting the code for the Multi Head Latent Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28b107d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ayush\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"c:\\Users\\ayush\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"c:\\Users\\ayush\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"c:\\Users\\ayush\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\Users\\ayush\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\traitlets\\config\\application.py\", line 976, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\Users\\ayush\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\Users\\ayush\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\Users\\ayush\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\base_events.py\", line 596, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\Users\\ayush\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\base_events.py\", line 1890, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\Users\\ayush\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\ayush\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"c:\\Users\\ayush\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"c:\\Users\\ayush\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n",
      "    await result\n",
      "  File \"c:\\Users\\ayush\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"c:\\Users\\ayush\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 383, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"c:\\Users\\ayush\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"c:\\Users\\ayush\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"c:\\Users\\ayush\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2936, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"c:\\Users\\ayush\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"c:\\Users\\ayush\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3135, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"c:\\Users\\ayush\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3338, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"c:\\Users\\ayush\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3398, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\ayush\\AppData\\Local\\Temp\\ipykernel_29072\\686997754.py\", line 1, in <cell line: 1>\n",
      "    import torch\n",
      "  File \"c:\\Users\\ayush\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\__init__.py\", line 870, in <module>\n",
      "    from . import _masked\n",
      "  File \"c:\\Users\\ayush\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\_masked\\__init__.py\", line 420, in <module>\n",
      "    def sum(input: Tensor,\n",
      "  File \"c:\\Users\\ayush\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\_masked\\__init__.py\", line 223, in _apply_docstring_templates\n",
      "    example_input = torch.tensor([[-3, -2, -1], [0, 1, 2]])\n",
      "c:\\Users\\ayush\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\_masked\\__init__.py:223: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at  C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_numpy.cpp:68.)\n",
      "  example_input = torch.tensor([[-3, -2, -1], [0, 1, 2]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f99b2047",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RopelessMLA(nn.Module):\n",
    "    def __init__(self,d_model,n_heads,kv_latent_dim):\n",
    "        super().__init__()\n",
    "        self.d_model=d_model\n",
    "        self.n_heads=n_heads\n",
    "        self.dh=d_model//n_heads ## Dimension per head\n",
    "\n",
    "        ## Projection layers\n",
    "        self.W_q=nn.Linear(d_model,d_model,bias=False) ## Query Projection\n",
    "        self.W_dkv=nn.Linear(d_model,kv_latent_dim,bias=False) ## Compress into latent kv space\n",
    "        self.W_uk=nn.Linear(kv_latent_dim,d_model,bias=False) ## Decompress K\n",
    "        self.W_uv=nn.Linear(kv_latent_dim,d_model,bias=False) ## Decompress V\n",
    "        self.W_o=nn.Linear(d_model,d_model,bias=False)  ## Final Output projection\n",
    "        \n",
    "\n",
    "        self.ln=nn.LayerNorm(kv_latent_dim)\n",
    "        self.register_buffer(\"absorbed_k\",None) ### Holds w_q @ W_uk\n",
    "\n",
    "    def forward(self,x,kv_cache=None,past_length=0):\n",
    "            B,S,D=x.size()\n",
    "            ## Compute absorbed_k once : W_q @ W_uk ,shape: (D,latent_dim)\n",
    "            if self.absorbed_k is None :\n",
    "                absorbed=torch.matmul(self.W_q.weight,self.W_uk.weight) ## (D,latent_dim)\n",
    "                self.absorbed_k=absorbed.view(self.n_heads,self.dh,-1) ## (n_heads,dh,latent_dim)\n",
    "            \n",
    "            ## Compress x into latent KV Space\n",
    "            new_c_kv=self.ln(self.W_dkv(x)) ## (B,S,latent_dim)\n",
    "            if kv_cache is None:\n",
    "                c_kv=new_c_kv\n",
    "            else:\n",
    "                c_kv=torch.cat((kv_cache,new_c_kv),dim=1) ## (B_total,latent_dim)\n",
    "            S_full=c_kv.size(1)\n",
    "            \n",
    "            ## Decompress V to full d_model and split into Heads\n",
    "            v_full=self.W_uv(c_kv)  ## (B,S_full,D)\n",
    "            v=v_full.view(B,S_full,self.n_heads,self.dh).transpose(1,2) ## (B,S,n_heads,dh)\n",
    "\n",
    "            ## Use input  x directly (Since W_q is absorbed)\n",
    "            q=x.view(B,S,self.n_heads,self.dh) ## (B,S,n_heads,dh)\n",
    "            \n",
    "            ## Compute attention scores\n",
    "            attn_scores=torch.zeros(B,self.n_heads,S,S_full,device=x.device)\n",
    "            for h in range(self.n_heads):\n",
    "                tmp=torch.matmul(q[:,  :,h],self.absorbed_k[h])\n",
    "                attn_scores[:,h]=torch.bmm(tmp,c_kv.transpose(1,2))\n",
    "\n",
    "            ## Scale and Apply Causal Mask\n",
    "\n",
    "            attn_scores=attn_scores/(self.dh*0.5)\n",
    "            mask=torch.tril(torch.ones((S,S_full),device=x.device),diagonal=past_length)\n",
    "            attn_scores=attn_scores.masked_fill(mask.view(1,1,S,S_full)==0,float('-inf'))\n",
    "\n",
    "            ## Apply Softmax to get attention weights\n",
    "            attn_weights=torch.softmax(attn_scores,dim=-1) ## (B,n_heads,S,S_full)\n",
    "\n",
    "            ## Apply attention weights to each heads V separately\n",
    "            out_heads=[]\n",
    "            for h in range(self.n_heads):\n",
    "                context_h=torch.bmm(attn_weights[:,h],v[:,h])  ## (B,S,dh)\n",
    "                out_heads.append(context_h)\n",
    "            ## Concentenate all head outputs along the feature dimension\n",
    "            out=torch.cat(out_heads,dim=-1)  ## (B,S,D)\n",
    "            return self.W_o(out),c_kv ## Final output projection updated latent cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c80430bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=RopelessMLA(d_model=512,n_heads=8,kv_latent_dim=256)\n",
    "x=torch.randn(1,5,512) ## Batch=2,context_length=10,d_model=512\n",
    "out,cache=model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4bb479",
   "metadata": {},
   "source": [
    "## Step 2 Memory Testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "631c9d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: torch.Size([1, 5, 512]), Cache: torch.Size([1, 5, 256])\n",
      "Memory: Standard=80.0kb ,Latent=20.0KB,Reduction=4.0\n"
     ]
    }
   ],
   "source": [
    "def demo ():\n",
    "    model=RopelessMLA(d_model=512,n_heads=8,kv_latent_dim=256)\n",
    "    x=torch.randn(1,5,512) ## Batch=2,context_length=10,d_model=512\n",
    "    out,cache=model(x)\n",
    "    print(f\"Output: {out.shape}, Cache: {cache.shape}\")\n",
    "\n",
    "    ## Memory Consumption\n",
    "    std_size=2*2*10*512*4/1024\n",
    "    latent_size=2*10*256*4/1024\n",
    "    print(f\"Memory: Standard={std_size:.1f}kb ,Latent={latent_size:.1f}KB,Reduction={std_size/latent_size}\")\n",
    "\n",
    "\n",
    "if __name__ ==\"__main__\":\n",
    "    demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecfea03",
   "metadata": {},
   "source": [
    "## STEP 3 : Cache testing - Single new infernece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f0c9e0a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step  : Inital input\n",
      "Output shape: torch.Size([1, 5, 8])\n",
      "cache shape:  torch.Size([1, 5, 4])\n",
      "Step  : Appended input\n",
      "Output shape: torch.Size([1, 1, 8])\n",
      "cache shape:  torch.Size([1, 6, 4])\n"
     ]
    }
   ],
   "source": [
    "def demo_cache_usage():\n",
    "    torch.manual_seed(0)\n",
    "    model=RopelessMLA(d_model=8,n_heads=2,kv_latent_dim=4)\n",
    "\n",
    "    ## -----Step 1 Initial input (Sequence of 5 Tokens)-------\n",
    "    x_1=torch.randn(1,5,8) ## (Batch=1,tokens(S)=5,D=8)\n",
    "    out1,cache1=model(x_1)\n",
    "    print(\"Step  : Inital input\")\n",
    "    print(f\"Output shape: {out1.shape}\")\n",
    "    print(f\"cache shape:  {cache1.shape}\")  ## Expect: (1,5,4)\n",
    "\n",
    "    ## Step 2: Append 1 Toekn ---\n",
    "    x_2=torch.randn(1,1,8) ## (Batch=1,tokens(S)=1,D=8)\n",
    "    out2,cache2=model(x_2,kv_cache=cache1,past_length=5)\n",
    "\n",
    "    print(\"Step  : Appended input\")\n",
    "    print(f\"Output shape: {out2.shape}\")\n",
    "    print(f\"cache shape:  {cache2.shape}\")  ## Expect: (1,6,4)\n",
    "demo_cache_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315cb9c1",
   "metadata": {},
   "source": [
    "## STEP 4 Cache Testing - Multiple new Inferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "685044de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial input of 50 tokens -> cache shape: torch.Size([1, 50, 4])\n",
      "Step 1: Added  1 Token -> cache shape torch.Size([1, 51, 4])\n",
      "Step 2: Added  1 Token -> cache shape torch.Size([1, 52, 4])\n",
      "Step 3: Added  1 Token -> cache shape torch.Size([1, 53, 4])\n",
      "Step 4: Added  1 Token -> cache shape torch.Size([1, 54, 4])\n"
     ]
    }
   ],
   "source": [
    "def demo_kv_cache_growth(num_initial_tokens=5,num_new_tokens=3):\n",
    "    torch.manual_seed(0)\n",
    "\n",
    "    model=RopelessMLA(d_model=8,n_heads=2,kv_latent_dim=4)\n",
    "\n",
    "    ## Step 1 Start with initial token batch\n",
    "    x=torch.randn(1,num_initial_tokens,8)\n",
    "    out,cache=model(x)\n",
    "    print(f\"Initial input of {num_initial_tokens} tokens -> cache shape:\", cache.shape)\n",
    "\n",
    "    ## Step Incrementally append new tokens one at a time\n",
    "    for step in range(1,num_new_tokens+1):\n",
    "        x_new = torch.randn(1, 1, 8)  # New token with the same feature dimension\n",
    "        out, cache = model(x_new,kv_cache=cache,past_length=cache.shape[1])\n",
    "        print(f\"Step {step}: Added  1 Token -> cache shape\", cache.shape)\n",
    "demo_kv_cache_growth(num_initial_tokens=50,num_new_tokens=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd9483a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
