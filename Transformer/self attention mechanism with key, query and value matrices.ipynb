{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPLEMENTING SELF ATTENTION WITH TRAINABLE WEIGHTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ayush\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "inputs = torch.tensor(\n",
    "  [[0.43, 0.15, 0.89], # Your     (x^1)\n",
    "   [0.55, 0.87, 0.66], # journey  (x^2)\n",
    "   [0.57, 0.85, 0.64], # starts   (x^3)\n",
    "   [0.22, 0.58, 0.33], # with     (x^4)\n",
    "   [0.77, 0.25, 0.10], # one      (x^5)\n",
    "   [0.05, 0.80, 0.55]] # step     (x^6)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "Let's begin by defining a few variables:\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "#A The second input element\n",
    "\n",
    "#B The input embedding size, d=3\n",
    "\n",
    "\n",
    "#C The output embedding size, d_out=2\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_2=inputs[1] #A\n",
    "d_in=inputs.shape[1] #B\n",
    "d_out=2 #C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "Note that in GPT-like models, the input and output dimensions are usually the same. \n",
    "\n",
    "But for illustration purposes, to better follow the computation, we choose different input (d_in=3)\n",
    "and output (d_out=2) dimensions here.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "Next, we initialize the three weight matrices Wq, Wk and Wv\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "W_query=torch.nn.Parameter(torch.rand(d_in,d_out),requires_grad=False)\n",
    "W_key=torch.nn.Parameter(torch.rand(d_in,d_out),requires_grad=False)\n",
    "W_value=torch.nn.Parameter(torch.rand(d_in,d_out),requires_grad=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[0.2961, 0.5166],\n",
      "        [0.2517, 0.6886],\n",
      "        [0.0740, 0.8665]])\n"
     ]
    }
   ],
   "source": [
    "print(W_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[0.0756, 0.1966],\n",
      "        [0.3164, 0.4017],\n",
      "        [0.1186, 0.8274]])\n"
     ]
    }
   ],
   "source": [
    "print(W_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[0.1366, 0.1025],\n",
      "        [0.1841, 0.7264],\n",
      "        [0.3153, 0.6871]])\n"
     ]
    }
   ],
   "source": [
    "print(W_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[0.0756, 0.1966],\n",
      "        [0.3164, 0.4017],\n",
      "        [0.1186, 0.8274]])\n"
     ]
    }
   ],
   "source": [
    "print(W_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "Note that we are setting requires_grad=False to reduce clutter in the outputs for\n",
    "illustration purposes. \n",
    "\n",
    "If we were to use the weight matrices for model training, we\n",
    "would set requires_grad=True to update these matrices during model training.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "Next, we compute the query, key, and value vectors as shown earlier\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5500, 0.8700, 0.6600])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4306, 1.4551])\n",
      "tensor([0.4433, 1.1419])\n",
      "tensor([0.3951, 1.0037])\n"
     ]
    }
   ],
   "source": [
    "query_2=x_2 @ W_query\n",
    "print(query_2)\n",
    "key_2=x_2 @ W_key\n",
    "print(key_2)\n",
    "value_2=x_2 @ W_value\n",
    "print(value_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "As we can see based on the output for the query, this results in a 2-dimensional vector. \n",
    "\n",
    "This is because: we set the number of columns of the corresponding weight matrix, via d_out, to 2:\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "Even though our temporary goal is to only compute the one context vector z(2),  we still\n",
    "require the key and value vectors for all input elements. \n",
    "\n",
    "This is because they are involved in computing the attention weights with respect to the query q(2)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "We can obtain all keys and values via matrix multiplication:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys.shape torch.Size([6, 2])\n",
      "values.shape torch.Size([6, 2])\n"
     ]
    }
   ],
   "source": [
    "queries=inputs @ W_query\n",
    "keys=inputs @ W_key\n",
    "values=inputs @ W_value\n",
    "\n",
    "print(\"Keys.shape\",keys.shape)\n",
    "print(\"values.shape\",values.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "As we can tell from the outputs, we successfully projected the 6 input tokens from a 3D\n",
    "onto a 2D embedding space:\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "First, let's compute the attention score Ï‰22</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.8524)\n"
     ]
    }
   ],
   "source": [
    "keys_2=keys[1] #A\n",
    "\n",
    "attn_score_22=query_2.dot(key_2)\n",
    "print(attn_score_22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "Again, we can generalize this computation to all attention scores via matrix multiplication:</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3669, 0.4433, 0.4361, 0.2408, 0.1827, 0.3275],\n",
       "        [0.7646, 1.1419, 1.1156, 0.6706, 0.3292, 0.9642]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4306, 1.4551])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.2705, 1.8524, 1.8111, 1.0795, 0.5577, 1.5440])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_score_2=query_2 @ keys.T # ALL ATTENTION SCORES FOR GIVEN QUERY\n",
    "attn_score_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9231, 1.3545, 1.3241, 0.7910, 0.4032, 1.1330],\n",
       "        [1.2705, 1.8524, 1.8111, 1.0795, 0.5577, 1.5440],\n",
       "        [1.2544, 1.8284, 1.7877, 1.0654, 0.5508, 1.5238],\n",
       "        [0.6973, 1.0167, 0.9941, 0.5925, 0.3061, 0.8475],\n",
       "        [0.6114, 0.8819, 0.8626, 0.5121, 0.2707, 0.7307],\n",
       "        [0.8995, 1.3165, 1.2871, 0.7682, 0.3937, 1.0996]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_scores=queries @ keys.T\n",
    "attn_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    \n",
    "We compute the attention weights by scaling the\n",
    "attention scores and using the softmax function we used earlier. \n",
    "\n",
    "The difference to earlier is\n",
    "that we now scale the attention scores by dividing them by the square root of the\n",
    "embedding dimension of the keys. \n",
    "\n",
    "Note that taking the square root is mathematically the\n",
    "same as exponentiating by 0.5:</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1500, 0.2264, 0.2199, 0.1311, 0.0906, 0.1820])\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "d_k=keys.shape[-1]\n",
    "attn_weights_2=torch.softmax(attn_score_2/d_k**0.5,dim=-1)\n",
    "print(attn_weights_2)\n",
    "print(d_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BUT WHY SQRT?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "Reason 1: For stability in learning\n",
    "\n",
    "The softmax function is sensitive to the magnitude of its inputs.when the inputs are large , the difference between the exponent values of each inputs become much more pronouned.This causes the Softmax output to become peaky where the highest vlaue recieves almost all the possibiles mass and the rest recieve very little.\n",
    "\n",
    "In attention mechanism , particulary in transformer if the dot product between the query and key is become large the attention score can be very large.This result in very sharp disturbtion making the model overly confident in one particular key such sharp disturbtion can make the learning unstable\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Softmax Without Scaling :  tensor([0.1925, 0.1426, 0.2351, 0.1426, 0.2872])\n",
      "Softmax With Scaling :  tensor([0.0326, 0.0030, 0.1615, 0.0030, 0.8000])\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "## DEFINE THE TENSOR \n",
    "tensor=torch.tensor([0.1,-0.2,0.3,-0.2,0.5])\n",
    "\n",
    "## APPLY SOFTMAX WITTHOUT SCALING\n",
    "softmax_result=torch.softmax(tensor,dim=-1)\n",
    "print(\"Softmax Without Scaling : \",softmax_result)\n",
    "\n",
    "## MULTIPLY THE TENSOR BY 8 AND THEN APPLY SOFTMAX\n",
    "scaled_tensor=tensor*8\n",
    "softmax_scaled_result=torch.softmax(scaled_tensor,dim=-1)\n",
    "print(\"Softmax With Scaling : \",softmax_scaled_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BUT WHY SQRT ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    \n",
    "Reason 2 : To make the variance of the dot product stable\n",
    "\n",
    "The dot product of Q and K increase the variance because multiplying two randoms numbers increases the variance\n",
    "\n",
    "The increas in variance grows with the \n",
    "dimensions.\n",
    "\n",
    "Dividing by sqrt (dim) Keeps the variance close to 1.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "## FUNCTION TO COMPUT VARIANCE BEFORE AND AFTER THE SCALING\n",
    "def compute_variance(dim,num_trails=1000):\n",
    "    dot_products=[]\n",
    "    scaled_dot_products=[]\n",
    "\n",
    "    ## GENERATE MULTIPLE RANDOM VECTORS AND COMPUTE DOT PRODUCTS\n",
    "    for _ in range(num_trails):\n",
    "        q=np.random.randn(dim)\n",
    "        k=np.random.randn(dim)\n",
    "\n",
    "        ## COMPUTE DOT PRODUCT\n",
    "        dot_product=np.dot(q,k)\n",
    "        dot_products.append(dot_product)\n",
    "\n",
    "        ## SCALED THE DOT PRODUCT BY SQRT(DIM)\n",
    "        scaled_dot_product=dot_product/np.sqrt(dim)\n",
    "        scaled_dot_products.append(scaled_dot_product)\n",
    "\n",
    "    ## CALCULATE VARIANCE OF THE DOT PRODUCTS\n",
    "    variance_before_scaling=np.var(dot_products)\n",
    "    variance_after_scaling=np.var(scaled_dot_products)\n",
    "    return variance_before_scaling, variance_after_scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance before scaling dimension(5): 5.030631223250378\n",
      "Variance after scaling dimension(5): 1.0061262446500754\n",
      "Variance before scaling dimension(100): 101.62535022288134\n",
      "Variance after scaling dimension(100) 1.0162535022288135\n"
     ]
    }
   ],
   "source": [
    "## FOR DIMENSION 5\n",
    "variance_before_5,variance_after_5=compute_variance(5)\n",
    "print(\"Variance before scaling dimension(5):\",variance_before_5)\n",
    "print(\"Variance after scaling dimension(5):\",variance_after_5)\n",
    "## FOR DIMENSION 20\n",
    "variance_before_100,variance_after_100=compute_variance(100)\n",
    "print(\"Variance before scaling dimension(100):\",variance_before_100)\n",
    "print(\"Variance after scaling dimension(100)\",variance_after_100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    \n",
    "We now compute the context vector as a weighted sum over the value\n",
    "vectors. \n",
    "\n",
    "Here, the attention weights serve as a weighting factor that weighs the respective\n",
    "importance of each value vector. \n",
    "\n",
    "We can use matrix multiplication to\n",
    "obtain the output in one step:</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3061, 0.8210])\n"
     ]
    }
   ],
   "source": [
    "context_vec_2 = attn_weights_2 @ values\n",
    "print(context_vec_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    \n",
    "So far, we only computed a single context vector, z(2). \n",
    "\n",
    "In the next section, we will generalize the code to compute all context vectors in the input sequence, z(1)to z (T)</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPLEMENTING A COMPACT SELF ATTENTION PYTHON CLASS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    \n",
    "In the previous sections, we have gone through a lot of steps to compute the self-attention\n",
    "outputs. \n",
    "\n",
    "This was mainly done for illustration purposes so we could go through one step at\n",
    "a time. \n",
    "\n",
    "In practice, with the LLM implementation in the next chapter in mind, it is helpful to\n",
    "organize this code into a Python class as follows:\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SelfAttention_v1(nn.Module):\n",
    "    def __init__(self,d_in,d_out):\n",
    "        super().__init__()\n",
    "        self.W_query=nn.Parameter(torch.rand(d_in,d_out))\n",
    "        self.W_key=nn.Parameter(torch.rand(d_in,d_out))\n",
    "        self.W_value=nn.Parameter(torch.rand(d_in,d_out))\n",
    "    def forward(self,x):\n",
    "        keys=x @ self.W_key\n",
    "        queries=x @ self.W_query\n",
    "        values=x @ self.W_value\n",
    "\n",
    "        attn_scores=queries @ keys.T\n",
    "        attn_weights=torch.softmax(attn_scores/keys.shape[-1]**0.5,dim=-1)\n",
    "        context_vec=attn_weights @ values\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "In this PyTorch code, SelfAttention_v1 is a class derived from nn.Module, which is a\n",
    "fundamental building block of PyTorch models, which provides necessary functionalities for\n",
    "model layer creation and management.    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "The __init__ method initializes trainable weight matrices (W_query, W_key, and\n",
    "W_value) for queries, keys, and values, each transforming the input dimension d_in to an\n",
    "output dimension d_out.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "During the forward pass, using the forward method, we compute the attention scores\n",
    "(attn_scores) by multiplying queries and keys, normalizing these scores using softmax.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    \n",
    "Finally, we create a context vector by weighting the values with these normalized attention\n",
    "scores.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2996, 0.8053],\n",
      "        [0.3061, 0.8210],\n",
      "        [0.3058, 0.8203],\n",
      "        [0.2948, 0.7939],\n",
      "        [0.2927, 0.7891],\n",
      "        [0.2990, 0.8040]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "sa_v1=SelfAttention_v1(d_in,d_out)\n",
    "print(sa_v1(inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "Since inputs contains six embedding vectors, we get a matrix storing the six\n",
    "context vectors, as shown in the above result. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "As a quick check, notice how the second row ([0.3061, 0.8210]) matches the contents of\n",
    "context_vec_2 in the previous section.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "We can improve the SelfAttention_v1 implementation further by utilizing PyTorch's\n",
    "nn.Linear layers, which effectively perform matrix multiplication when the bias units are\n",
    "disabled. \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "Additionally, a significant advantage of using nn.Linear instead of manually\n",
    "implementing nn.Parameter(torch.rand(...)) is that nn.Linear has an optimized weight\n",
    "initialization scheme, contributing to more stable and effective model training.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention_v2(nn.Module):\n",
    "    \n",
    "    def __init__(self, d_in, d_out, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key   = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        keys = self.W_key(x)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "        \n",
    "        attn_scores = queries @ keys.T\n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "\n",
    "        context_vec = attn_weights @ values\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "You can use the SelfAttention_v2 similar to SelfAttention_v1:\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0739,  0.0713],\n",
      "        [-0.0748,  0.0703],\n",
      "        [-0.0749,  0.0702],\n",
      "        [-0.0760,  0.0685],\n",
      "        [-0.0763,  0.0679],\n",
      "        [-0.0754,  0.0693]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(789)\n",
    "sa_v2 = SelfAttention_v2(d_in, d_out)\n",
    "print(sa_v2(inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "Note that SelfAttention_v1 and SelfAttention_v2 give different outputs because they\n",
    "use different initial weights for the weight matrices since nn.Linear uses a more\n",
    "sophisticated weight initialization scheme.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
