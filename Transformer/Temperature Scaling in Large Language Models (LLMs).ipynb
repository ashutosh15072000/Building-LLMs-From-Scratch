{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DECODING STRATEGY 1: TEMPERATURE SCALING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "Previously, inside the generate_text_simple function, we always sampled the token\n",
    "with the highest probability as the next token using torch.argmax, also known as greedy\n",
    "decoding. \n",
    "\n",
    "To generate text with more variety, we can replace the argmax with a function\n",
    "that samples from a probability distribution (here, the probability scores the LLM generates\n",
    "for each vocabulary entry at each token generation step).\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "To illustrate the probabilistic sampling with a concrete example, let's briefly discuss the\n",
    "next-token generation process using a very small vocabulary for illustration purposes:\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab={\n",
    "        \"closer\": 0,\n",
    "    \"every\": 1, \n",
    "    \"effort\": 2, \n",
    "    \"forward\": 3,\n",
    "    \"inches\": 4,\n",
    "    \"moves\": 5, \n",
    "    \"pizza\": 6,\n",
    "    \"toward\": 7,\n",
    "    \"you\": 8,\n",
    "\n",
    "}\n",
    "\n",
    "inverse_vocab={v:k for k,v in vocab.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "Next, assume the LLM is given the start context \"every effort moves you\" and\n",
    "generates the following next-token logits:\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ayush\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 4.5100,  0.8900, -1.9000,  6.7500,  1.6300, -1.6200, -1.8900,  6.2800,\n",
       "         1.7900])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_token_logits=torch.tensor([4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79])\n",
    "next_token_logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "As discussed in the previous chapter, inside the generate_text_simple, we convert the\n",
    "logits into probabilities via the softmax function and obtain the token ID corresponding the\n",
    "generated token via the argmax function, which we can then map back into text via the\n",
    "inverse vocabulary:\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(sci_mode=False,precision=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([    0.0609,     0.0016,     0.0001,     0.5721,     0.0034,     0.0001,\n",
      "            0.0001,     0.3576,     0.0040])\n",
      "3\n",
      "forward\n"
     ]
    }
   ],
   "source": [
    "probas=torch.softmax(next_token_logits,dim=0)\n",
    "print(probas)\n",
    "next_token_id = torch.argmax(probas).item()\n",
    "\n",
    "print(next_token_id)\n",
    "\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "To implement a probabilistic sampling process, we can now replace the argmax with the\n",
    "multinomial function in PyTorch:\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "next_token_id = torch.multinomial(probas, num_samples=1).item()\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "The printed output is \"forward\" just like before. What happened? The multinomial\n",
    "function samples the next token proportional to its probability score. \n",
    "\n",
    "In other words,\n",
    "\"forward\" is still the most likely token and will be selected by multinomial most of the\n",
    "time but not all the time. \n",
    "\n",
    "To illustrate this, let's implement a function that repeats this\n",
    "sampling 1000 times:\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73 x closer\n",
      "0 x every\n",
      "0 x effort\n",
      "582 x forward\n",
      "2 x inches\n",
      "0 x moves\n",
      "0 x pizza\n",
      "343 x toward\n"
     ]
    }
   ],
   "source": [
    "def print_sampled_tokens(probas):\n",
    "    torch.manual_seed(123) # Manual seed for reproducibility\n",
    "    sample = [torch.multinomial(probas, num_samples=1).item() for i in range(1_000)]\n",
    "    sampled_ids = torch.bincount(torch.tensor(sample))\n",
    "    for i, freq in enumerate(sampled_ids):\n",
    "        print(f\"{freq} x {inverse_vocab[i]}\")\n",
    "\n",
    "print_sampled_tokens(probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "As we can see based on the output, the word \"forward\" is sampled most of the time (582\n",
    "out of 1000 times), but other tokens such as \"closer\", \"inches\", and \"toward\" will also\n",
    "be sampled some of the time. \n",
    "\n",
    "This means that if we replaced the argmax function with the\n",
    "multinomial function inside the generate_and_print_sample function, the LLM would\n",
    "sometimes generate texts such as \"every effort moves you toward\", \"every effort\n",
    "moves you inches\", and \"every effort moves you closer\" instead of \"every effort\n",
    "moves you forward\".\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "We can further control the distribution and selection process via a concept called\n",
    "temperature scaling, where temperature scaling is just a fancy description for dividing the\n",
    "logits by a number greater than 0:\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "Temperatures greater than 1 result in more uniformly distributed token probabilities,\n",
    "and Temperatures smaller than 1 will result in more confident (sharper or more peaky)\n",
    "distributions.\n",
    "\n",
    "Let's illustrate this by plotting the original probabilities alongside\n",
    "probabilities scaled with different temperature values:\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_with_temperature(logits, temperature):\n",
    "    scaled_logits = logits / temperature\n",
    "    return torch.softmax(scaled_logits, dim=0)\n",
    "\n",
    "# Temperature values\n",
    "temperatures = [1, 0.1, 5]  # Original, higher confidence, and lower confidence\n",
    "\n",
    "# Calculate scaled probabilities\n",
    "scaled_probas = [softmax_with_temperature(next_token_logits, T) for T in temperatures]\n",
    "\n",
    "##Multinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting\n",
    "x = torch.arange(len(vocab))\n",
    "bar_width = 0.15\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 3))\n",
    "for i, T in enumerate(temperatures):\n",
    "    rects = ax.bar(x + i * bar_width, scaled_probas[i], bar_width, label=f'Temperature = {T}')\n",
    "\n",
    "ax.set_ylabel('Probability')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(vocab.keys(), rotation=90)\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"temperature-plot.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "A temperature of 1 divides the logits by 1 before passing them to the softmax function to\n",
    "compute the probability scores. \n",
    "\n",
    "In other words, using a temperature of 1 is the same as not\n",
    "using any temperature scaling. \n",
    "\n",
    "In this case, the tokens are selected with a probability equal\n",
    "to the original softmax probability scores via the multinomial sampling function in PyTorch.    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "Applying very small temperatures, such as 0.1, will\n",
    "result in sharper distributions such that the behavior of the multinomial function selects\n",
    "the most likely token (here: \"forward\") almost 100% of the time, approaching the\n",
    "behavior of the argmax function. \n",
    "\n",
    "Vice versa, a temperature of 5 results in a more uniform\n",
    "distribution where other tokens are selected more often. \n",
    "\n",
    "This can add more variety to the\n",
    "generated texts but also more often results in nonsensical text. \n",
    "\n",
    "For example, using the\n",
    "temperature of 5 results in texts such as \"every effort moves you pizza\" about 4% of\n",
    "the time.\n",
    "    \n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
