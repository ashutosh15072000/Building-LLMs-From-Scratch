{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1iTjWrPopNU"
      },
      "source": [
        "### Let us code Mixture of Experts (MoE) From Stratch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2Eejq6mo1fT"
      },
      "source": [
        "### Step 0 Load packages and import data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2V5nUyRomV1",
        "outputId": "e119c60c-6adc-4d1b-9d21-a83371ee7e2f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f35f01d9a10>"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## import the necessary packages and set for reproductibity.For this notebook , pytorch is all you need\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "torch.manual_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJ99QrR_pidX",
        "outputId": "56f02994-d469-47d6-a0d3-4086fa5d460c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-05-19 07:34:23--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘input.txt’\n",
            "\n",
            "\rinput.txt             0%[                    ]       0  --.-KB/s               \rinput.txt           100%[===================>]   1.06M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2025-05-19 07:34:23 (23.9 MB/s) - ‘input.txt’ saved [1115394/1115394]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "## Downloading the tiny shapespare dataset\n",
        "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXl26pIBqnRb"
      },
      "source": [
        "### Step 1 Define each expert as a neural network\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![alt text](IMG/number_of_experts.jpg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "StKIuXKErddc"
      },
      "outputs": [],
      "source": [
        "## Expert Module\n",
        "class Expert(nn.Module):\n",
        "  \"\"\"An MLP is a simple linear layer followed by non linearuty i.e each expert\"\"\"\n",
        "\n",
        "  def __init__(self, n_embed,dropout):\n",
        "    super().__init__()\n",
        "    self.net=nn.Sequential(\n",
        "        nn.Linear(n_embed,4*n_embed),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(4*n_embed,n_embed),\n",
        "        nn.Dropout(dropout)\n",
        "\n",
        "\n",
        "    )\n",
        "  def forward(self,x):\n",
        "    return self.net(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rxsfsETt4Ck"
      },
      "source": [
        "### Step 2: Implement the Router"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![alt text](<IMG/Routing Matrix.jpg>)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzX1VcehuZPb"
      },
      "source": [
        "The router , determines which expert network recieves the output for each token from the multi head attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "plgt86M9qlt7",
        "outputId": "b2a4286a-af2a-46f1-92b4-b255cb1add99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[ 0.0238, -0.2771, -0.5070],\n",
            "         [-0.5727, -0.9081,  0.1839],\n",
            "         [ 0.8137,  0.1781,  1.5661],\n",
            "         [ 0.6523,  0.4525,  0.0062]]], grad_fn=<ViewBackward0>)\n"
          ]
        }
      ],
      "source": [
        "## Understanding how gating works\n",
        "num_experts=3\n",
        "top_k=2\n",
        "n_embed=8\n",
        "\n",
        "## Example of multi head attention output for a simple illustrative example consider n_embed=32 ,context length=\n",
        "\n",
        "mh_output=torch.randn(1,4,n_embed)\n",
        "\n",
        "routing_matrix=nn.Linear(n_embed,num_experts) ## nn.Linear(32,4)\n",
        "\n",
        "expert_selector_matrix=routing_matrix(mh_output) ## (1,4,4)\n",
        "\n",
        "print(expert_selector_matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7YlZu-cvy4z"
      },
      "source": [
        "### Step 3 : Implement Topk Load Balancing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![alt text](<IMG/expert selector matrix.jpg>)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJMtsJeAqNCr",
        "outputId": "f8d4fcfc-351e-49ef-e730-57e5d0bca83f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[ 0.0238, -0.2771],\n",
            "         [ 0.1839, -0.5727],\n",
            "         [ 1.5661,  0.8137],\n",
            "         [ 0.6523,  0.4525]]], grad_fn=<TopkBackward0>)\n",
            "tensor([[[0, 1],\n",
            "         [2, 0],\n",
            "         [2, 0],\n",
            "         [0, 1]]])\n"
          ]
        }
      ],
      "source": [
        "top_k_logits,top_k_indices=expert_selector_matrix.topk(top_k,dim=-1) ## Get top-k experts\n",
        "print(top_k_logits)\n",
        "print(top_k_indices)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwxswQQrwkGj"
      },
      "source": [
        "### Step 4: Use -inf and apply Softmax"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![alt text](<IMG/apply softmax on expert matrix.jpg>)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSw015W9wKNa",
        "outputId": "c5d0f23c-dd58-42ce-dcc5-49533a28b73a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[ 0.0238, -0.2771,    -inf],\n",
            "         [-0.5727,    -inf,  0.1839],\n",
            "         [ 0.8137,    -inf,  1.5661],\n",
            "         [ 0.6523,  0.4525,    -inf]]], grad_fn=<ScatterBackward0>)\n"
          ]
        }
      ],
      "source": [
        "## Full_like clones a tensor and fill it with a specified value\n",
        "zeros=torch.full_like(expert_selector_matrix,float(\"-inf\"))\n",
        "sparse_logits=zeros.scatter(-1,top_k_indices,top_k_logits)\n",
        "print(sparse_logits)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVEzU_TCw4LY",
        "outputId": "dd02fb74-9fe2-43d7-ccf3-6d76978727db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[0.5747, 0.4253, 0.0000],\n",
            "         [0.3194, 0.0000, 0.6806],\n",
            "         [0.3203, 0.0000, 0.6797],\n",
            "         [0.5498, 0.4502, 0.0000]]], grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ],
      "source": [
        "gating_output=F.softmax(sparse_logits,dim=-1)\n",
        "print(gating_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtvI0TzWx-pj"
      },
      "source": [
        "### Step 5: Creare a class for TopKRoting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "9Qwr1Hj5x9J3"
      },
      "outputs": [],
      "source": [
        "## First define the topk router module\n",
        "class TopkRouter(nn.Module):\n",
        "  def __init__(self,n_embed,num_experts,top_k) :\n",
        "    super(TopkRouter,self).__init__()\n",
        "    self.top_k=top_k\n",
        "    self.linear=nn.Linear(n_embed,num_experts)\n",
        "\n",
        "\n",
        "  def forward(self,mh_output):\n",
        "    ## mh_output is the output tensor from multihead self attention block\n",
        "\n",
        "    routing_matirx=self.linear(mh_output)\n",
        "\n",
        "    top_k_logits,top_k_indices=routing_matirx.topk(self.top_k,dim=-1)\n",
        "\n",
        "    zeros=torch.full_like(routing_matirx,float(\"-inf\"))\n",
        "\n",
        "    sparse_logits=zeros.scatter(-1,top_k_indices,top_k_logits)\n",
        "\n",
        "    expert_select_weight_matrix=F.softmax(sparse_logits,dim=-1)\n",
        "\n",
        "    return expert_select_weight_matrix,top_k_indices\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WwvzXP9GzNHc",
        "outputId": "ae5db73b-5877-4c95-dd5a-4039fde045c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(tensor([[[0.6177, 0.0000, 0.3823],\n",
            "         [0.6445, 0.3555, 0.0000],\n",
            "         [0.0000, 0.3600, 0.6400],\n",
            "         [0.5666, 0.4334, 0.0000]]], grad_fn=<SoftmaxBackward0>), tensor([[[0, 2],\n",
            "         [0, 1],\n",
            "         [2, 1],\n",
            "         [0, 1]]]))\n"
          ]
        }
      ],
      "source": [
        "### Testing this out:\n",
        "num_experts=3\n",
        "top_k=2\n",
        "n_embed=8\n",
        "\n",
        "mh_output=torch.randn(1,4,n_embed)\n",
        "\n",
        "top_k_gate=TopkRouter(n_embed,num_experts,top_k)\n",
        "\n",
        "router_output=top_k_gate(mh_output)\n",
        "\n",
        "print(router_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GRjtbSI0V9D"
      },
      "source": [
        "### Step 6: Create a class for NosiyTopkRouting\n",
        "\n",
        "![alt text](<IMG/Noisy Top K Routing.jpg>)\n",
        "\n",
        "Nosiy top k gating is an important tool in training Moe models\n",
        "\n",
        "Essentially you dont want all the tokens to sent to the same set of favoured experts.\n",
        "\n",
        "You want a fine balance of exploration and exploitation.for this purpose ,to load balance ,it is helpful to add standard normal to logits from the gating linear layer.This makes training more efficient.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "5IKFpjqGz1kT"
      },
      "outputs": [],
      "source": [
        "## Changing the above to accomdate nosiy top k gating\n",
        "\n",
        "class NoisyTopkRouter(nn.Module):\n",
        "  def __init__(self,n_embed,num_experts,top_k):\n",
        "    super(NoisyTopkRouter,self).__init__()\n",
        "    self.top_k=top_k\n",
        "\n",
        "    ## Layer for router logits\n",
        "    self.topkroute_linear=nn.Linear(n_embed,num_experts)\n",
        "    self.noise_linear=nn.Linear(n_embed,num_experts)\n",
        "\n",
        "\n",
        "  def forward(self,mh_output):\n",
        "    ## Mh_output is the output tensor from multihead self attention block\n",
        "\n",
        "    logits=self.topkroute_linear(mh_output)\n",
        "\n",
        "    ## Noise logits\n",
        "    noise_logits=self.noise_linear(mh_output)\n",
        "\n",
        "    ## Adding scaled unit gaussian noise to the logits\n",
        "    noise=torch.randn_like(logits)*F.softplus(noise_logits)\n",
        "\n",
        "    logits=logits+noise\n",
        "\n",
        "    top_k_logits,top_k_indices=logits.topk(self.top_k,dim=-1)\n",
        "\n",
        "    zeros=torch.full_like(logits,float(\"-inf\"))\n",
        "\n",
        "    sparse_logits=zeros.scatter(-1,top_k_indices,top_k_logits)\n",
        "\n",
        "    expert_selector_weight_matrix=F.softmax(sparse_logits,dim=-1)\n",
        "\n",
        "    return expert_selector_weight_matrix,top_k_indices\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mlWkfpbz6cKk",
        "outputId": "0a4c9213-927b-473b-9881-52ccc711e844"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[ 0.0238, -0.2771, -0.5070],\n",
            "         [-0.5727, -0.9081,  0.1839],\n",
            "         [ 0.8137,  0.1781,  1.5661],\n",
            "         [ 0.6523,  0.4525,  0.0062]]], grad_fn=<ViewBackward0>)\n",
            "tensor([[[3, 1],\n",
            "         [0, 2],\n",
            "         [3, 1],\n",
            "         [3, 1]]])\n"
          ]
        }
      ],
      "source": [
        "### Testing this out , again\n",
        "num_experts=4\n",
        "top_k=2\n",
        "n_embed=8\n",
        "\n",
        "mh_output=torch.randn(1,4,n_embed)\n",
        "\n",
        "top_k_gate=NoisyTopkRouter(n_embed,num_experts,top_k)\n",
        "\n",
        "expert_selector_weight_matrix,indices=top_k_gate(mh_output)\n",
        "print(expert_selector_matrix)\n",
        "print(indices)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-OBQd4z6vvz"
      },
      "source": [
        "### Step 7: Create the sparse Mixture of experts (Moe)\n",
        "\n",
        "![alt text](<IMG/expert calculations.jpg>)\n",
        "\n",
        "![alt text](<IMG/expert cal 1.jpg>)\n",
        "\n",
        "![alt text](<IMG/expert cal 2.jpg>)\n",
        "\n",
        "- The primary aspect of this process involves the expert selector weight matrix.\n",
        "\n",
        "- After acquiring the expert selector weight matrix,top k values are selectively multipied with the outputs from the corresponding top-k\n",
        "experts for a given token.\n",
        "\n",
        "- This Selective multiplication forms a weighted sum, which constitues the spareseMoe blocks output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ltcj4vI8ma9X",
        "outputId": "c633162a-8bf9-4da2-f228-364be42b67b7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([4, 8])"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "flat_x=mh_output.view(-1,mh_output.size(-1))\n",
        "flat_x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXbiCTVmpkt_",
        "outputId": "4ac7e5e0-bea8-4ba3-c007-5e21ce0c94e0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[0.0000, 0.3531, 0.0000, 0.6469],\n",
              "         [0.9226, 0.0000, 0.0774, 0.0000],\n",
              "         [0.0000, 0.4685, 0.0000, 0.5315],\n",
              "         [0.0000, 0.2103, 0.0000, 0.7897]]], grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "expert_selector_weight_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "V6BTFeIAeyyx"
      },
      "outputs": [],
      "source": [
        "expert=nn.ModuleList([Expert(n_embed,0) for _ in range(num_experts)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1sSyvm62gTUP",
        "outputId": "1462c173-deba-481e-fc15-39b9c2f7b7fc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[3, 1],\n",
              "         [0, 2],\n",
              "         [3, 1],\n",
              "         [3, 1]]])"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1CoLd9_uMwI",
        "outputId": "36763010-f463-4e51-b9d6-97525a9bfdae"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[False, False],\n",
              "         [ True, False],\n",
              "         [False, False],\n",
              "         [False, False]]])"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "indices==0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqNrLwbUh-_n",
        "outputId": "8e2b9cbf-65eb-4db5-c63b-a330b00203bf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([4])"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "flat_mask=(indices==0).any(dim=-1).view(-1)\n",
        "flat_mask.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqXookmcmQHw",
        "outputId": "cf0646d4-4ecf-46e7-b8f6-bd6581eb96e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 0.3416, -0.2214,  1.2554, -0.7150,  0.8539,  0.5130,  0.5397,  0.5655]])\n",
            "tensor([[ 0.1063,  0.1303,  0.1469,  0.0185, -0.2671,  0.0029, -0.0806, -0.0068]],\n",
            "       grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ],
      "source": [
        "if flat_mask.any():\n",
        "  expert_input=flat_x[flat_mask]\n",
        "  print(expert_input)\n",
        "  expert_output=expert[0](expert_input)\n",
        "  print(expert_output)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0egVcOgo5Hx",
        "outputId": "f2a71689-4f8e-488a-8f35-8d46bd2bc0f5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.0000, 0.3531, 0.0000, 0.6469],\n",
              "        [0.9226, 0.0000, 0.0774, 0.0000],\n",
              "        [0.0000, 0.4685, 0.0000, 0.5315],\n",
              "        [0.0000, 0.2103, 0.0000, 0.7897]], grad_fn=<ViewBackward0>)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "flat_expert_selector_weight_matrix=expert_selector_weight_matrix.view(-1,expert_selector_weight_matrix.size(1))\n",
        "flat_expert_selector_weight_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "UWhdAXippqVv"
      },
      "outputs": [],
      "source": [
        "gating_scores=flat_expert_selector_weight_matrix[flat_mask,0].unsqueeze(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ParfoygSTIa",
        "outputId": "99534792-262a-4c87-9a60-00ef993be0d9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 0.0980,  0.1202,  0.1356,  0.0171, -0.2465,  0.0027, -0.0743, -0.0063]],\n",
              "       grad_fn=<MulBackward0>)"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "weighted_output=expert_output*gating_scores\n",
        "weighted_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iu0fjcDeSlGS",
        "outputId": "f01c1c3c-72cc-454b-b4e2-662cf840efa9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 0.0980,  0.1202,  0.1356,  0.0171, -0.2465,  0.0027, -0.0743, -0.0063]],\n",
              "       grad_fn=<SqueezeBackward1>)"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "weighted_output.squeeze(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "7ZZForKicLxQ"
      },
      "outputs": [],
      "source": [
        "class SparseMoE(nn.Module):\n",
        "  def __init__(self,n_embed,num_experts,top_k):\n",
        "     super(SparseMoE,self).__init__()\n",
        "     self.router=NoisyTopkRouter(n_embed,num_experts,top_k)\n",
        "     self.experts=nn.ModuleList([Expert(n_embed,0) for _ in range(num_experts)])\n",
        "\n",
        "  def forward(self,x):\n",
        "    ## GETTING THE EXPERT SELECT WEIGHT MATRIX AND INDICES\n",
        "    expert_selector_weight_matrix,indices=self.router(x)\n",
        "\n",
        "    ## CREATE TENSOR FOR OUTPUT OF SIZE OF MHA OUTPUT\n",
        "    final_output=torch.zeros_like(x)\n",
        "\n",
        "    ## RESHAPE INPUTS FOR BATCH PROCESSING\n",
        "\n",
        "    flat_x=x.view(-1,x.size(-1))\n",
        "\n",
        "    flat_expert_selector_weight_matrix=expert_selector_weight_matrix.view(-1,expert_selector_weight_matrix.size(-1))\n",
        "\n",
        "    ## PROCESS EACH EXPERT IN PARALLEL\n",
        "    for i,expert in enumerate(self.experts):\n",
        "      ## CREATE A MASK FOR THE INPUTS WHERE THE CURRENT EXPERTS IS IN TOP K\n",
        "\n",
        "      ## IT GIVE A TRUE AND FALSE VALUE FOR EACH EXPERT WHERE THE TOKEN IS SELECT FOR THAT EXPERT.\n",
        "      expert_mask=(indices==i).any(dim=-1)\n",
        "      flat_mask=expert_mask.view(-1)\n",
        "\n",
        "      if flat_mask.any():\n",
        "        ## IT FILTER OUT TOKENS FROM THE MHA OUTPUT FOR SELECT EXPERT.\n",
        "        expert_input=flat_x[flat_mask]\n",
        "        ## AND THEN OUTPUT SENT TO EXPERT\n",
        "        expert_output=expert(expert_input)\n",
        "\n",
        "        ## EXTRACT AND APPLY GATING SCORES\n",
        "        gating_scores=flat_expert_selector_weight_matrix[flat_mask,i].unsqueeze(1)\n",
        "\n",
        "        weighted_output=gating_scores*expert_output\n",
        "\n",
        "        ## UPDATE FINAL OUTPUT ADDITIVELY BY INDEXING AND ADDING.\n",
        "        final_output[expert_mask]=weighted_output.squeeze(1)\n",
        "\n",
        "    return final_output\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVZdAKUnUXWq",
        "outputId": "65151d05-347a-4c67-933c-272eb5228a0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of the final Output: torch.Size([4, 8, 16])\n",
            "tensor([[[-9.4351e-02,  2.5056e-01, -7.4708e-02,  8.4360e-02,  2.6926e-01,\n",
            "           1.4315e-01, -3.4850e-01,  1.2705e-01, -6.9078e-02,  1.9349e-01,\n",
            "          -2.3063e-02,  8.1250e-02, -1.4750e-01,  2.3005e-01, -1.3541e-01,\n",
            "          -1.4158e-01],\n",
            "         [-5.1728e-02,  1.3329e-01,  2.3243e-01,  2.0983e-01, -1.2289e-01,\n",
            "          -1.1335e-01, -8.7145e-02,  9.0008e-02, -2.0408e-02,  2.6926e-02,\n",
            "           6.0160e-02,  2.1683e-01,  1.6879e-01,  1.7361e-01,  2.7809e-02,\n",
            "           1.7415e-01],\n",
            "         [-6.4685e-02,  7.3002e-02, -2.3478e-02, -3.5024e-02,  1.7841e-02,\n",
            "           3.7098e-02,  1.5010e-01,  2.2208e-01,  2.3342e-02,  6.4208e-02,\n",
            "          -1.8596e-02, -3.7774e-02,  4.1073e-02, -5.6595e-02, -6.7111e-03,\n",
            "          -1.5239e-01],\n",
            "         [-4.5738e-01,  1.5445e-01,  2.3443e-01, -1.2563e-01,  1.3437e-01,\n",
            "          -3.3661e-01,  2.4439e-01,  4.4006e-01,  1.2974e-01,  1.1116e-01,\n",
            "           3.1039e-01,  1.6280e-01,  4.8311e-02,  3.3020e-01, -7.6863e-02,\n",
            "           2.9885e-01],\n",
            "         [ 3.1502e-01, -1.2698e-01,  1.0426e-01, -1.1965e-01,  3.0952e-01,\n",
            "          -4.0354e-01, -3.4575e-01, -1.1553e-01, -4.1097e-01,  7.5026e-02,\n",
            "          -1.6342e-01, -4.1991e-01,  9.6150e-02, -1.3211e-01, -9.2982e-02,\n",
            "           3.7591e-02],\n",
            "         [-8.6977e-03,  1.0560e-01,  3.3722e-01,  4.0658e-03, -1.4621e-01,\n",
            "          -2.8795e-01,  4.7806e-02, -1.3957e-02,  1.9670e-03,  8.0871e-02,\n",
            "           1.8766e-01, -5.8347e-03, -1.3546e-02,  8.9971e-02,  2.3861e-01,\n",
            "           7.9527e-02],\n",
            "         [-1.9314e-02, -9.5402e-02, -4.8744e-03, -7.8633e-02,  9.4229e-02,\n",
            "          -5.1870e-03,  2.0483e-03, -2.8411e-03,  9.5947e-05,  1.8982e-02,\n",
            "           1.2493e-01,  1.8675e-02,  2.4189e-02,  8.0863e-02, -1.9044e-01,\n",
            "          -4.4628e-02],\n",
            "         [-6.3711e-02, -6.3688e-02,  1.9354e-01,  7.3109e-02,  2.7518e-02,\n",
            "           3.5036e-02,  3.7704e-02, -7.5646e-02,  7.9179e-02, -1.0811e-02,\n",
            "           2.4632e-01,  1.2996e-01, -1.4180e-01,  2.2599e-01, -7.2787e-02,\n",
            "           4.8796e-02]],\n",
            "\n",
            "        [[ 6.8717e-02,  3.1171e-02, -1.2328e-02, -2.1939e-01,  1.8129e-01,\n",
            "           2.8644e-02,  3.7230e-01,  4.0642e-01,  7.9558e-02, -8.2119e-02,\n",
            "           1.1900e-01, -9.0779e-02,  1.4391e-01, -4.8544e-02,  1.5461e-02,\n",
            "          -1.1734e-01],\n",
            "         [ 4.7725e-02, -1.0800e-02,  1.1399e-03, -5.6261e-02,  1.1444e-01,\n",
            "          -1.3643e-01, -2.0821e-03, -2.3416e-02,  1.1355e-01, -2.2013e-02,\n",
            "          -4.3253e-03, -1.5722e-01,  5.6618e-02,  8.5560e-02, -1.9822e-01,\n",
            "          -1.2253e-01],\n",
            "         [ 9.1500e-02, -2.9820e-02,  1.6187e-01, -3.0336e-02, -1.4574e-02,\n",
            "          -2.9073e-02, -3.0066e-02, -1.2125e-01,  9.9346e-02,  1.3249e-01,\n",
            "           6.6297e-02, -2.3941e-03,  3.0018e-02,  1.6646e-01, -5.8930e-02,\n",
            "          -5.4632e-02],\n",
            "         [-5.2619e-02,  2.2268e-02,  1.3215e-01,  3.4856e-02, -6.4995e-02,\n",
            "           7.5386e-03, -1.7578e-03, -2.3006e-02, -2.5956e-02,  2.9361e-02,\n",
            "           6.7800e-02,  2.4066e-02,  1.4610e-02,  4.8831e-02,  3.7946e-02,\n",
            "          -5.4871e-02],\n",
            "         [ 1.0407e-01,  1.0852e-01,  2.2161e-02, -4.8283e-02,  4.5156e-02,\n",
            "          -8.9607e-02, -3.5284e-02, -2.5454e-03,  7.5802e-02, -3.3981e-02,\n",
            "          -6.1751e-02, -8.8070e-02, -9.1930e-02,  2.3113e-03,  1.1329e-02,\n",
            "          -3.5221e-02],\n",
            "         [-5.4101e-02,  1.3502e-01,  1.0841e-02, -3.8883e-02,  1.2364e-01,\n",
            "           8.3722e-02, -3.7164e-02,  8.7759e-02, -2.8171e-02,  3.9209e-02,\n",
            "          -3.2235e-02, -6.3264e-02, -6.8286e-02,  2.2972e-02,  9.1967e-02,\n",
            "          -8.6499e-02],\n",
            "         [ 2.3535e-01,  1.9174e-02,  2.2949e-01,  3.0185e-01,  1.1232e-01,\n",
            "          -5.9884e-02,  1.4620e-01, -1.5661e-01,  1.4490e-01,  3.8743e-02,\n",
            "          -8.1610e-02, -2.6333e-01, -2.7480e-01,  1.9607e-01, -1.5887e-01,\n",
            "          -2.3322e-01],\n",
            "         [-1.3671e-02, -5.4921e-03,  5.9628e-02, -3.2704e-02,  1.2128e-01,\n",
            "          -1.4793e-02, -4.1654e-02, -2.8960e-03, -4.3228e-02,  8.3236e-02,\n",
            "           7.6710e-03,  2.5298e-03,  7.5827e-03,  4.0967e-02, -1.0845e-01,\n",
            "          -6.7626e-02]],\n",
            "\n",
            "        [[-2.1673e-01,  3.9387e-01,  3.7880e-01,  1.9422e-01, -2.2247e-02,\n",
            "          -4.6145e-02, -1.2182e-01, -6.4644e-02, -1.3439e-01, -3.1390e-01,\n",
            "           7.2193e-02,  2.1750e-01,  2.3072e-01,  2.2255e-01,  2.0579e-01,\n",
            "           3.7109e-01],\n",
            "         [ 3.3934e-01,  8.6104e-02, -1.3728e-01, -2.0078e-02,  3.5259e-01,\n",
            "          -1.1010e-02,  7.3702e-02,  1.2426e-01,  3.9585e-02, -1.0282e-01,\n",
            "           2.3075e-01,  9.2384e-02, -9.1965e-02,  7.6732e-02, -3.0810e-01,\n",
            "          -1.1768e-01],\n",
            "         [-9.2779e-02,  1.0844e-01,  2.1556e-01,  1.7483e-01,  3.6886e-02,\n",
            "          -1.9308e-01, -1.6477e-01, -3.0309e-02,  5.5731e-02,  8.7660e-02,\n",
            "           2.2184e-01,  9.6747e-03, -4.1265e-03,  3.5548e-01,  8.7982e-03,\n",
            "          -3.0169e-02],\n",
            "         [-1.0737e-01,  4.9141e-02,  2.2957e-01,  6.7745e-02,  1.0624e-02,\n",
            "          -5.6203e-02, -8.5788e-02, -5.8121e-02, -8.7236e-02, -7.1893e-02,\n",
            "           6.8262e-02,  1.0276e-01,  4.4511e-02,  1.4049e-01,  1.2664e-01,\n",
            "           3.1958e-02],\n",
            "         [ 3.0796e-01,  1.3270e-01,  1.6050e-02,  3.2258e-02,  6.1205e-02,\n",
            "          -8.3530e-02,  2.3546e-01,  8.0854e-02,  1.3215e-01,  4.3396e-04,\n",
            "          -1.1984e-01, -6.7399e-02,  4.0605e-04,  7.5956e-02, -3.7002e-01,\n",
            "          -2.3577e-01],\n",
            "         [-1.3116e-01,  9.3582e-02,  5.2429e-01,  5.6371e-02, -2.4853e-01,\n",
            "          -1.3705e-01, -1.3093e-01, -8.1223e-02,  5.5367e-02,  1.2134e-01,\n",
            "           1.4276e-01, -1.2500e-01,  1.8204e-01,  3.6355e-01, -3.2529e-02,\n",
            "           4.3407e-02],\n",
            "         [ 1.1876e-01, -9.5387e-02,  1.1575e-01, -3.0485e-02, -5.6508e-02,\n",
            "          -3.0606e-02, -4.3913e-02, -1.2901e-01,  9.4887e-02,  2.1284e-01,\n",
            "           1.6350e-01,  7.8694e-02,  3.5913e-02,  1.0103e-01, -2.7419e-02,\n",
            "          -8.9747e-02],\n",
            "         [ 5.6937e-02,  4.8079e-02, -9.3390e-02,  1.2560e-02,  2.8828e-01,\n",
            "           7.9907e-02,  8.7081e-02,  1.0082e-01, -1.5476e-01,  1.6521e-01,\n",
            "          -1.0186e-01,  6.5735e-02,  2.9454e-02,  6.2002e-02, -8.0275e-02,\n",
            "          -7.1036e-02]],\n",
            "\n",
            "        [[-2.9681e-02,  5.1437e-02,  1.5128e-01,  6.0189e-04, -6.1838e-02,\n",
            "          -1.0786e-01, -3.2694e-02,  5.4877e-02,  6.3140e-02,  4.9913e-02,\n",
            "           2.2968e-02,  7.5821e-02, -2.1266e-02,  7.8521e-02,  7.6649e-02,\n",
            "          -2.7879e-02],\n",
            "         [ 1.5661e-03,  9.0664e-02,  1.5338e-01,  4.4539e-03, -8.7397e-02,\n",
            "          -1.0838e-01, -3.8610e-02, -5.6656e-02,  5.5099e-02,  5.8869e-02,\n",
            "           4.0375e-02,  6.7148e-02,  4.5099e-02,  1.5514e-01,  2.6519e-02,\n",
            "          -1.2168e-02],\n",
            "         [-1.0894e-01, -3.0132e-02,  2.3462e-01,  1.5866e-01, -2.0259e-01,\n",
            "          -2.9233e-01,  1.1003e-01, -6.4510e-02,  1.9605e-01,  3.0730e-01,\n",
            "           9.5598e-03,  1.1296e-01, -1.4405e-02,  2.8007e-01,  1.2678e-02,\n",
            "           7.7732e-02],\n",
            "         [ 3.7455e-03, -7.9049e-04,  3.9199e-01,  1.1941e-01, -1.6927e-01,\n",
            "           1.1913e-02, -4.8543e-02, -3.3168e-01, -5.5079e-02,  6.4514e-02,\n",
            "          -1.9655e-02, -2.2473e-02,  4.7704e-02,  2.4535e-01,  9.4150e-02,\n",
            "          -1.7063e-01],\n",
            "         [-7.9255e-03,  9.1116e-02,  1.2363e-01,  1.1258e-01, -9.5181e-02,\n",
            "          -2.6982e-02, -3.9053e-02, -1.1658e-01,  6.9595e-02,  8.5277e-02,\n",
            "           1.7428e-02,  3.9739e-02, -6.0287e-02,  1.5553e-01,  5.8906e-03,\n",
            "          -6.8459e-03],\n",
            "         [ 8.6186e-02, -2.0645e-01,  2.0032e-01,  1.1067e-02, -1.7007e-01,\n",
            "          -1.8067e-01, -2.7927e-01,  6.4217e-02, -1.1475e-01,  6.1490e-02,\n",
            "          -8.8917e-02, -7.7935e-01,  8.2720e-02, -7.7881e-02,  1.1944e-01,\n",
            "           7.5242e-02],\n",
            "         [ 2.0043e-02, -5.8211e-02,  2.4666e-01,  1.8180e-01, -1.5984e-01,\n",
            "          -1.1268e-01, -1.8572e-01, -1.2050e-01,  1.5065e-01,  1.2115e-01,\n",
            "           1.4790e-01,  7.6696e-02, -2.8687e-01,  1.8270e-01,  7.8002e-02,\n",
            "          -1.0578e-01],\n",
            "         [-3.1151e-03,  5.8249e-03,  1.0024e-01,  2.7320e-02, -8.4531e-02,\n",
            "          -2.9785e-02, -9.3035e-02, -6.9542e-02,  6.2249e-03,  4.0963e-02,\n",
            "           5.6917e-02,  6.4120e-02, -4.2307e-02,  9.7514e-02,  6.1927e-02,\n",
            "          -2.5782e-02]]], grad_fn=<IndexPutBackward0>)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "## Let's test this output\n",
        "num_experts=3\n",
        "top_k=2\n",
        "n_embed=16\n",
        "dropout=0.1\n",
        "mh_output=torch.randn(4,8,n_embed) ## Example multi Head Attention Output\n",
        "sparse_moe=SparseMoE(n_embed,num_experts,top_k)\n",
        "final_output=sparse_moe(mh_output)\n",
        "print(\"Shape of the final Output:\",final_output.shape)\n",
        "print(final_output)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_t6B6chDg_2Z"
      },
      "source": [
        "## **STEP : Putting together all the building blocks of MoE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "oaLNAVGtUX82"
      },
      "outputs": [],
      "source": [
        "## EXPERT MODULE\n",
        "## Expert Module\n",
        "class Expert(nn.Module):\n",
        "  \"\"\"An MLP is a simple linear layer followed by non linearuty i.e each expert\"\"\"\n",
        "\n",
        "  def __init__(self, n_embed,dropout):\n",
        "    super().__init__()\n",
        "    self.net=nn.Sequential(\n",
        "        nn.Linear(n_embed,4*n_embed),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(4*n_embed,n_embed),\n",
        "        nn.Dropout(dropout)\n",
        "\n",
        "\n",
        "    )\n",
        "  def forward(self,x):\n",
        "    return self.net(x)\n",
        "\n",
        "## CHANGING THE ABOVE TO ACCOMDATE NOISY TOP K GATING\n",
        "\n",
        "class NoisyTopkRouter(nn.Module):\n",
        "  def __init__(self,n_embed,num_experts,top_k):\n",
        "    super(NoisyTopkRouter,self).__init__()\n",
        "    self.top_k=top_k\n",
        "\n",
        "    ## Layer for router logits\n",
        "    self.topkroute_linear=nn.Linear(n_embed,num_experts)\n",
        "    self.noise_linear=nn.Linear(n_embed,num_experts)\n",
        "\n",
        "\n",
        "  def forward(self,mh_output):\n",
        "    ## Mh_output is the output tensor from multihead self attention block\n",
        "\n",
        "    logits=self.topkroute_linear(mh_output)\n",
        "\n",
        "    ## Noise logits\n",
        "    noise_logits=self.noise_linear(mh_output)\n",
        "\n",
        "    ## Adding scaled unit gaussian noise to the logits\n",
        "    noise=torch.randn_like(logits)*F.softplus(noise_logits)\n",
        "\n",
        "    logits=logits+noise\n",
        "\n",
        "    top_k_logits,top_k_indices=logits.topk(self.top_k,dim=-1)\n",
        "\n",
        "    zeros=torch.full_like(logits,float(\"-inf\"))\n",
        "\n",
        "    sparse_logits=zeros.scatter(-1,top_k_indices,top_k_logits)\n",
        "\n",
        "    expert_selector_weight_matrix=F.softmax(sparse_logits,dim=-1)\n",
        "\n",
        "    return expert_selector_weight_matrix,top_k_indices\n",
        "\n",
        "\n",
        "## CREATE THE SPARSE MIXTURE OF EXPERTS MODULE\n",
        "class SparseMoE(nn.Module):\n",
        "  def __init__(self,n_embed,num_experts,top_k):\n",
        "     super(SparseMoE,self).__init__()\n",
        "     self.router=NoisyTopkRouter(n_embed,num_experts,top_k)\n",
        "     self.experts=nn.ModuleList([Expert(n_embed,0) for _ in range(num_experts)])\n",
        "\n",
        "  def forward(self,x):\n",
        "    ## GETTING THE EXPERT SELECT WEIGHT MATRIX AND INDICES\n",
        "    expert_selector_weight_matrix,indices=self.router(x)\n",
        "\n",
        "    ## CREATE TENSOR FOR OUTPUT OF SIZE OF MHA OUTPUT\n",
        "    final_output=torch.zeros_like(x)\n",
        "\n",
        "    ## RESHAPE INPUTS FOR BATCH PROCESSING\n",
        "\n",
        "    flat_x=x.view(-1,x.size(-1))\n",
        "\n",
        "    flat_expert_selector_weight_matrix=expert_selector_weight_matrix.view(-1,expert_selector_weight_matrix.size(-1))\n",
        "\n",
        "    ## PROCESS EACH EXPERT IN PARALLEL\n",
        "    for i,expert in enumerate(self.experts):\n",
        "      ## CREATE A MASK FOR THE INPUTS WHERE THE CURRENT EXPERTS IS IN TOP K\n",
        "\n",
        "      ## IT GIVE A TRUE AND FALSE VALUE FOR EACH EXPERT WHERE THE TOKEN IS SELECT FOR THAT EXPERT.\n",
        "      expert_mask=(indices==i).any(dim=-1)\n",
        "      flat_mask=expert_mask.view(-1)\n",
        "\n",
        "      if flat_mask.any():\n",
        "        ## IT FILTER OUT TOKENS FROM THE MHA OUTPUT FOR SELECT EXPERT.\n",
        "        expert_input=flat_x[flat_mask]\n",
        "        ## AND THEN OUTPUT SENT TO EXPERT\n",
        "        expert_output=expert(expert_input)\n",
        "\n",
        "        ## EXTRACT AND APPLY GATING SCORES\n",
        "        gating_scores=flat_expert_selector_weight_matrix[flat_mask,i].unsqueeze(1)\n",
        "\n",
        "        weighted_output=gating_scores*expert_output\n",
        "\n",
        "        ## UPDATE FINAL OUTPUT ADDITIVELY BY INDEXING AND ADDING.\n",
        "        final_output[expert_mask]=weighted_output.squeeze(1)\n",
        "\n",
        "    return final_output\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_NwM6BziFo4"
      },
      "source": [
        "## **Code the Entire transformer block: Part1 (Multi Head Attention)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![\n",
        "](IMG/mha_1jpg.jpg)\n",
        "\n",
        "![\n",
        "](IMG/mha_2.jpg)\n",
        "![alt text](IMG/mha_3.jpg)\n",
        "![alt text](IMG/mha_4.jpg)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "ar5IE5DGUX6s"
      },
      "outputs": [],
      "source": [
        "class Head(nn.Module):\n",
        "  \"\"\"One head of self attention\"\"\"\n",
        "\n",
        "  def __init__(self,head_size):\n",
        "    super().__init__()\n",
        "    self.key=nn.Linear(n_embed,head_size,bias=False)\n",
        "    self.query=nn.Linear(n_embed,head_size,bias=False)\n",
        "    self.value=nn.Linear(n_embed,head_size,bias=False)\n",
        "    self.register_buffer(\"tril\",torch.tril(torch.ones(block_size,block_size)))\n",
        "\n",
        "    self.dropout=nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self,x):\n",
        "    B,T,C=x.shape\n",
        "    k=self.key(x) ## (B,T,C)\n",
        "    q=self.query(x) ## (B,T,C)\n",
        "    ## Compute attention scores (\"affinities\")\n",
        "    wei=q @ k.transpose(-2,-1) * C**-0.5 ## (B,T,C) @ (B,C,T) -> (B,T,T)\n",
        "    wei=wei.masked_fill(self.tril[:T,:T]==0,float(\"-inf\")) ## (B,T,T)\n",
        "    wei=F.softmax(wei,dim=-1) ## (B,T,T)\n",
        "    wei=self.dropout(wei)\n",
        "    ## Perform the weighted aggregation of the values\n",
        "    v=self.value(x) ## (B,T,C)\n",
        "    out=wei@v ## (B,T,T)@(B,T,C)->(B,T,C)\n",
        "\n",
        "    return out\n",
        "\n",
        "## MULTIHEAD SELF ATTENTION\n",
        "class MultiHeadAttention(nn.Module):\n",
        "  \"\"\"Multiple heads of self attention in parallel\"\"\"\n",
        "\n",
        "  def __init__(self,num_heads,head_size):\n",
        "    super().__init__()\n",
        "    self.heads=nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
        "    self.proj=nn.Linear(n_embed,n_embed)\n",
        "    self.dropout=nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self,x):\n",
        "    out=torch.cat([h(x) for h in self.heads],dim=-1)\n",
        "    out=self.dropout(self.proj(out))\n",
        "    return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wl_gQHfZkVAZ"
      },
      "source": [
        "## **STEP 10: Code the Entire Transformer Block Part:2(Assemble all layers)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![alt text](IMG/transformer.jpg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "mkFPfP2WUX4K"
      },
      "outputs": [],
      "source": [
        "## First create a self attention +mixture of experts block that may be repeated several number of times\n",
        "## Copy pasting key architecture variables for clarity\n",
        "\n",
        "class Block(nn.Module):\n",
        "  \"\"\"Mixture of Experts Transformer block: Communicution followed by computation (multi head self atttention+sparse mixture of experts)\"\"\"\n",
        "  def __init__(self,n_embed,n_heads,num_experts,top_k,dropout):\n",
        "    super().__init__()\n",
        "    head_size=n_embed//n_heads\n",
        "    self.sa=MultiHeadAttention(n_heads,head_size)\n",
        "    self.moe=SparseMoE(n_embed,num_experts,top_k)\n",
        "    self.ln1=nn.LayerNorm(n_embed)\n",
        "    self.ln2=nn.LayerNorm(n_embed)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x=x+self.sa(self.ln1(x))\n",
        "    x=x+self.moe(self.ln2(x))\n",
        "    return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaVw0EzKmEnQ"
      },
      "source": [
        "## **STEP 11: Define Entire Language Model Architecture**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![alt text](IMG/sparse_modeljpg.jpg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "9x9UyaypUX2B"
      },
      "outputs": [],
      "source": [
        "## Finally putting it all together to create a sparse mixture of experts language model\n",
        "\n",
        "class SparseMoELanguageModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.token_embedding_table=nn.Embedding(vocab_size,n_embed)\n",
        "    self.position_embedding_table=nn.Embedding(block_size,n_embed)\n",
        "    self.blocks=nn.Sequential(*[Block(n_embed,n_heads,num_experts,top_k,dropout) for _ in range(n_layers)])\n",
        "    self.ln_f=nn.LayerNorm(n_embed)\n",
        "    self.lm_head=nn.Linear(n_embed,vocab_size)\n",
        "\n",
        "  def forward(self,idx,targets=None):\n",
        "    B,T=idx.shape\n",
        "\n",
        "    ## idx and targets are both (B,T) tensor of integers\n",
        "    tok_emb=self.token_embedding_table(idx) ## (B,T,C)\n",
        "    pos_emb=self.position_embedding_table(torch.arange(T,device=device)) ## (T,C)\n",
        "    x=tok_emb+pos_emb ## (B,T,C)\n",
        "    x=self.blocks(x) ## (B,T,C)\n",
        "    x=self.ln_f(x) ## (B,T,C)\n",
        "    logits=self.lm_head(x) ## (B,T,vocab_size)\n",
        "    if targets is None:\n",
        "      loss=None\n",
        "    else:\n",
        "      B,T,C=logits.shape\n",
        "      logits=logits.view(B*T,C)\n",
        "      targets=targets.view(B*T)\n",
        "      loss=F.cross_entropy(logits,targets)\n",
        "    return logits,loss\n",
        "\n",
        "  def generate(self,idx,max_new_tokens):\n",
        "    ## idx is (B,T) array of indices in the current context\n",
        "    for _ in range(max_new_tokens):\n",
        "      ## crop idx to the last block_size tokens\n",
        "      idx_cond=idx[:,-block_size:]\n",
        "      ## get the predictions\n",
        "      logits,loss=self(idx_cond)\n",
        "      ## focus only on the last time step\n",
        "      logits=logits[:,-1,:]\n",
        "      ## apply softmax to get probabilities\n",
        "      probs=F.softmax(logits,dim=-1) ## (B,C)\n",
        "      ## sample from the distribution\n",
        "      idx_next=torch.multinomial(probs,num_samples=1) ## (B,1)\n",
        "      ## Append sampled index to the running sequence\n",
        "      idx=torch.cat((idx,idx_next),dim=1) ## (B,T+1)\n",
        "    return idx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFOYWHmynppY"
      },
      "source": [
        "## **STEP 12: Creating Training and Testing Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "rNlwqsZwUXz4"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(1337)\n",
        "\n",
        "with open(\"input.txt\",\"r\",encoding=\"utf-8\") as f:\n",
        "  text=f.read()\n",
        "\n",
        "## Here are all the unique characters that occur in this text\n",
        "chars=sorted(list(set(text)))\n",
        "vocab_size=len(chars)\n",
        "\n",
        "## Create a mapping from characters to integers\n",
        "stoi={ch:i for i,ch in enumerate(chars)}\n",
        "itos={i:ch for i,ch in enumerate(chars)}\n",
        "encode=lambda s:[stoi[c] for c in s] ## encoder: take a string, output a list of integers\n",
        "decode=lambda l:\"\".join([itos[i] for i in l]) ## decoder: take a list of integers, output a string\n",
        "\n",
        "## Train and test splits\n",
        "data=torch.tensor(encode(text),dtype=torch.long)\n",
        "n=int(0.9*len(data))\n",
        "train_data=data[:n]\n",
        "val_data=data[n:]\n",
        "\n",
        "## Data Loading\n",
        "## Data Loading\n",
        "def get_batch(split):\n",
        "  ## Generate a small batch of data of inputs x and targets y\n",
        "  data=train_data if split==\"train\" else val_data\n",
        "  ix=torch.randint(len(data)-block_size,(batch_size,))\n",
        "  x=torch.stack([data[i:i+block_size] for i in ix])\n",
        "  y=torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "  # Move the tensors to the specified device\n",
        "  x, y = x.to(device), y.to(device)\n",
        "  return x,y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNmUMk9ApHZ4"
      },
      "source": [
        "## **STEP 13: Define LLM Loss**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "KshJdFFFUXxd"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def estimate_loss():\n",
        "  out={}\n",
        "  model.eval()\n",
        "  for split in [\"train\",\"val\"]:\n",
        "    losses=torch.zeros(eval_iters)\n",
        "    for k in range(eval_iters):\n",
        "      X,Y=get_batch(split)\n",
        "      logits,loss=model(X,Y)\n",
        "      losses[k]=loss.item()\n",
        "    out[split]=losses.mean()\n",
        "  model.train()\n",
        "  return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IegvL5jpUjJ"
      },
      "source": [
        "## **STEP 14: Define Training loop parameters and other hyperparameters**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "IbcBi53sUXu6"
      },
      "outputs": [],
      "source": [
        "## First defining hyperparameters and bioler plate code and data preparation code is repeated for convenice\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import init\n",
        "## Hyperparameters\n",
        "batch_size=16\n",
        "block_size=32\n",
        "max_iters=20\n",
        "eval_interval=100\n",
        "learning_rate=1e-3\n",
        "device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "eval_iters=400\n",
        "head_size=32\n",
        "n_layers=8\n",
        "n_heads=8\n",
        "dropout=0.1\n",
        "n_embed=128\n",
        "num_experts=8\n",
        "top_k=2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5l9uZM0xqY8g"
      },
      "source": [
        "## **STEP 15 : Initialize the Entire Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "D6q3Baz0UXsa"
      },
      "outputs": [],
      "source": [
        "def kaiming_init(m):\n",
        "  if isinstance(m,(nn.Linear)):\n",
        "    init.kaiming_uniform_(m.weight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1-RVNHJUXpc",
        "outputId": "3dc5e1cf-f4e3-4743-babb-583b5f48ed09"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SparseMoELanguageModel(\n",
              "  (token_embedding_table): Embedding(65, 128)\n",
              "  (position_embedding_table): Embedding(32, 128)\n",
              "  (blocks): Sequential(\n",
              "    (0): Block(\n",
              "      (sa): MultiHeadAttention(\n",
              "        (heads): ModuleList(\n",
              "          (0-7): 8 x Head(\n",
              "            (key): Linear(in_features=128, out_features=16, bias=False)\n",
              "            (query): Linear(in_features=128, out_features=16, bias=False)\n",
              "            (value): Linear(in_features=128, out_features=16, bias=False)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (proj): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (moe): SparseMoE(\n",
              "        (router): NoisyTopkRouter(\n",
              "          (topkroute_linear): Linear(in_features=128, out_features=8, bias=True)\n",
              "          (noise_linear): Linear(in_features=128, out_features=8, bias=True)\n",
              "        )\n",
              "        (experts): ModuleList(\n",
              "          (0-7): 8 x Expert(\n",
              "            (net): Sequential(\n",
              "              (0): Linear(in_features=128, out_features=512, bias=True)\n",
              "              (1): ReLU()\n",
              "              (2): Linear(in_features=512, out_features=128, bias=True)\n",
              "              (3): Dropout(p=0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (1): Block(\n",
              "      (sa): MultiHeadAttention(\n",
              "        (heads): ModuleList(\n",
              "          (0-7): 8 x Head(\n",
              "            (key): Linear(in_features=128, out_features=16, bias=False)\n",
              "            (query): Linear(in_features=128, out_features=16, bias=False)\n",
              "            (value): Linear(in_features=128, out_features=16, bias=False)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (proj): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (moe): SparseMoE(\n",
              "        (router): NoisyTopkRouter(\n",
              "          (topkroute_linear): Linear(in_features=128, out_features=8, bias=True)\n",
              "          (noise_linear): Linear(in_features=128, out_features=8, bias=True)\n",
              "        )\n",
              "        (experts): ModuleList(\n",
              "          (0-7): 8 x Expert(\n",
              "            (net): Sequential(\n",
              "              (0): Linear(in_features=128, out_features=512, bias=True)\n",
              "              (1): ReLU()\n",
              "              (2): Linear(in_features=512, out_features=128, bias=True)\n",
              "              (3): Dropout(p=0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (2): Block(\n",
              "      (sa): MultiHeadAttention(\n",
              "        (heads): ModuleList(\n",
              "          (0-7): 8 x Head(\n",
              "            (key): Linear(in_features=128, out_features=16, bias=False)\n",
              "            (query): Linear(in_features=128, out_features=16, bias=False)\n",
              "            (value): Linear(in_features=128, out_features=16, bias=False)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (proj): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (moe): SparseMoE(\n",
              "        (router): NoisyTopkRouter(\n",
              "          (topkroute_linear): Linear(in_features=128, out_features=8, bias=True)\n",
              "          (noise_linear): Linear(in_features=128, out_features=8, bias=True)\n",
              "        )\n",
              "        (experts): ModuleList(\n",
              "          (0-7): 8 x Expert(\n",
              "            (net): Sequential(\n",
              "              (0): Linear(in_features=128, out_features=512, bias=True)\n",
              "              (1): ReLU()\n",
              "              (2): Linear(in_features=512, out_features=128, bias=True)\n",
              "              (3): Dropout(p=0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (3): Block(\n",
              "      (sa): MultiHeadAttention(\n",
              "        (heads): ModuleList(\n",
              "          (0-7): 8 x Head(\n",
              "            (key): Linear(in_features=128, out_features=16, bias=False)\n",
              "            (query): Linear(in_features=128, out_features=16, bias=False)\n",
              "            (value): Linear(in_features=128, out_features=16, bias=False)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (proj): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (moe): SparseMoE(\n",
              "        (router): NoisyTopkRouter(\n",
              "          (topkroute_linear): Linear(in_features=128, out_features=8, bias=True)\n",
              "          (noise_linear): Linear(in_features=128, out_features=8, bias=True)\n",
              "        )\n",
              "        (experts): ModuleList(\n",
              "          (0-7): 8 x Expert(\n",
              "            (net): Sequential(\n",
              "              (0): Linear(in_features=128, out_features=512, bias=True)\n",
              "              (1): ReLU()\n",
              "              (2): Linear(in_features=512, out_features=128, bias=True)\n",
              "              (3): Dropout(p=0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (4): Block(\n",
              "      (sa): MultiHeadAttention(\n",
              "        (heads): ModuleList(\n",
              "          (0-7): 8 x Head(\n",
              "            (key): Linear(in_features=128, out_features=16, bias=False)\n",
              "            (query): Linear(in_features=128, out_features=16, bias=False)\n",
              "            (value): Linear(in_features=128, out_features=16, bias=False)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (proj): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (moe): SparseMoE(\n",
              "        (router): NoisyTopkRouter(\n",
              "          (topkroute_linear): Linear(in_features=128, out_features=8, bias=True)\n",
              "          (noise_linear): Linear(in_features=128, out_features=8, bias=True)\n",
              "        )\n",
              "        (experts): ModuleList(\n",
              "          (0-7): 8 x Expert(\n",
              "            (net): Sequential(\n",
              "              (0): Linear(in_features=128, out_features=512, bias=True)\n",
              "              (1): ReLU()\n",
              "              (2): Linear(in_features=512, out_features=128, bias=True)\n",
              "              (3): Dropout(p=0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (5): Block(\n",
              "      (sa): MultiHeadAttention(\n",
              "        (heads): ModuleList(\n",
              "          (0-7): 8 x Head(\n",
              "            (key): Linear(in_features=128, out_features=16, bias=False)\n",
              "            (query): Linear(in_features=128, out_features=16, bias=False)\n",
              "            (value): Linear(in_features=128, out_features=16, bias=False)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (proj): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (moe): SparseMoE(\n",
              "        (router): NoisyTopkRouter(\n",
              "          (topkroute_linear): Linear(in_features=128, out_features=8, bias=True)\n",
              "          (noise_linear): Linear(in_features=128, out_features=8, bias=True)\n",
              "        )\n",
              "        (experts): ModuleList(\n",
              "          (0-7): 8 x Expert(\n",
              "            (net): Sequential(\n",
              "              (0): Linear(in_features=128, out_features=512, bias=True)\n",
              "              (1): ReLU()\n",
              "              (2): Linear(in_features=512, out_features=128, bias=True)\n",
              "              (3): Dropout(p=0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (6): Block(\n",
              "      (sa): MultiHeadAttention(\n",
              "        (heads): ModuleList(\n",
              "          (0-7): 8 x Head(\n",
              "            (key): Linear(in_features=128, out_features=16, bias=False)\n",
              "            (query): Linear(in_features=128, out_features=16, bias=False)\n",
              "            (value): Linear(in_features=128, out_features=16, bias=False)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (proj): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (moe): SparseMoE(\n",
              "        (router): NoisyTopkRouter(\n",
              "          (topkroute_linear): Linear(in_features=128, out_features=8, bias=True)\n",
              "          (noise_linear): Linear(in_features=128, out_features=8, bias=True)\n",
              "        )\n",
              "        (experts): ModuleList(\n",
              "          (0-7): 8 x Expert(\n",
              "            (net): Sequential(\n",
              "              (0): Linear(in_features=128, out_features=512, bias=True)\n",
              "              (1): ReLU()\n",
              "              (2): Linear(in_features=512, out_features=128, bias=True)\n",
              "              (3): Dropout(p=0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (7): Block(\n",
              "      (sa): MultiHeadAttention(\n",
              "        (heads): ModuleList(\n",
              "          (0-7): 8 x Head(\n",
              "            (key): Linear(in_features=128, out_features=16, bias=False)\n",
              "            (query): Linear(in_features=128, out_features=16, bias=False)\n",
              "            (value): Linear(in_features=128, out_features=16, bias=False)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (proj): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (moe): SparseMoE(\n",
              "        (router): NoisyTopkRouter(\n",
              "          (topkroute_linear): Linear(in_features=128, out_features=8, bias=True)\n",
              "          (noise_linear): Linear(in_features=128, out_features=8, bias=True)\n",
              "        )\n",
              "        (experts): ModuleList(\n",
              "          (0-7): 8 x Expert(\n",
              "            (net): Sequential(\n",
              "              (0): Linear(in_features=128, out_features=512, bias=True)\n",
              "              (1): ReLU()\n",
              "              (2): Linear(in_features=512, out_features=128, bias=True)\n",
              "              (3): Dropout(p=0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "  )\n",
              "  (ln_f): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "  (lm_head): Linear(in_features=128, out_features=65, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model=SparseMoELanguageModel()\n",
        "model.apply(kaiming_init)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2SbnE5srdHK"
      },
      "source": [
        "## **STEP 16 : Run The Pre Training Loop**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMWN37ljrmY4",
        "outputId": "7f0b081f-5e2c-4253-bbdd-33261a6bb077"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8.996545 M parameters\n",
            "step 0: train loss 5.4057, val loss 5.3837\n",
            "step 100: train loss 2.6960, val loss 2.6898\n",
            "step 199: train loss 2.5163, val loss 2.5302\n"
          ]
        }
      ],
      "source": [
        "## Not using Mlflow\n",
        "m=model.to(device)\n",
        "## Print the number of parameters in the model\n",
        "print(sum(p.numel() for p in m.parameters())/1e6,\"M parameters\")\n",
        "\n",
        "## Create a PyTorch optimizer\n",
        "optimizer=torch.optim.AdamW(model.parameters(),lr=learning_rate)\n",
        "\n",
        "for iter in range(max_iters):\n",
        "  ## every once in a while evaluate the loss on train and val sets\n",
        "  if iter%eval_interval==0 or iter==max_iters-1:\n",
        "    losses=estimate_loss()\n",
        "    print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "\n",
        "  ## sample a batch of data\n",
        "  xb,yb=get_batch(\"train\")\n",
        "\n",
        "  ## Evaluate the loss\n",
        "  logits,loss=model(xb,yb)\n",
        "  optimizer.zero_grad(set_to_none=True)\n",
        "  loss.backward()\n",
        "  optimizer.step()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atizIYv9tciI"
      },
      "source": [
        "## STEP 17: Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JEwMf275tb6L",
        "outputId": "c105ccac-726f-46e5-eef1-175bc75e130e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "CClas\n",
            "Kp pe y wiso stathatherrd llathe y,\n",
            "th,\n",
            "Dha pofome me thisatr! po e toud vey, thesor he preng ak isor s wu.\n",
            "APAshrd w thiealo k d pesu t!\n",
            "I :\n",
            "\n",
            "OLB he inde!\n",
            "Ror d tofolrcpess? f cese cerormarnonowinkom, ard ttie cehe\n",
            "UK mr sthe thado sonwosCutthe gst uu hu f weinoinNo,Ulleand kedXer\n",
            "Dur the kidse irth arg er buw heng od,\n",
            "Wamr foplor myoucaf? lt nfw f t Yosond tthoondin ah, iger atonz?\n",
            "\n",
            "\n",
            "AROO:\n",
            "Kind mathit tord INII o thed these uthed y bfoond thuve sendesky trir\n",
            "\n",
            "Whitoipe hy thrort bo mm is ee, arro Angote?\n",
            "Whu e billartheBcand, cor ltimaivul rl funchenomt s;\n",
            "Ter\n",
            "D c;\n",
            "T hande manofa ben y ivendeeshet th!\n",
            "Anferd, swhe gunsural\n",
            "Tot thikinck cry d othor;\n",
            "Sothy borig oule brth fl-e te w.\n",
            "Tleld thethe then wo concucinle tose- ngnenete baver\n",
            "pbe.\n",
            "\n",
            "RLId md n on Bus pstond hine hasthe.\n",
            "WeXe hilt he path akn'se sy?\n",
            "PLourrw CWessimy d th!\n",
            "Whet mor w wanes, Four I myondtowe m I mmazeve Mive:\n",
            "He\n",
            "Se aton hevecagheoven, pw thod cakyyotow,\n",
            "Ye we, n chouoe kir oulagr, gn w nthe.\n",
            "\n",
            "Se malee sin tho thy wroft I R E blecalour th kay fldsewh s!\n",
            "PexGieremyocicoton thealpm. aerd wutealous.\n",
            "\n",
            "\n",
            "I stloy bis brrremese, thos sis cor, fn fangou lirp pos houerrsou:\n",
            "Thepl keris withy I Whistou,\n",
            "Nfo'ewout sll tontI, mpeean y tar an en,\n",
            "Yoke toln, ht hede pevowilonthel he I\n",
            "W ato I ecank of d bimy p tongunse,\n",
            "O,\n",
            "Gouse thonp d ce,-onou icoweas-\n",
            "Cir be r Wond hmigte foe to palotherntall,\n",
            "I te in theange me, oungto tomr nppaloned,\n",
            "Nuid; RWe ts Wharitont,\n",
            "Yer, 's it s'ndentharlarf houibeie and\n",
            "I\n",
            "AUPan wing s oulloth d the the, wonthe,\n",
            "Tiy tou tshance.\n",
            "\n",
            "OOHlwiprtoy is the wathorsorsb s om trrseved poul?\n",
            "DullaOOUtede prtond patongage k ton thu powmnt, buordgr;\n",
            "File the wit\n",
            "Po pr, theve, sncuuchest thm, man, me athoooussir, dimed Ans, co Ind ale;\n",
            "Weruektll f t f doe pu I manpave beer o ust nour fesongand.\n",
            "\n",
            "\n",
            "CAurithaende CCWh meil wourie;\n",
            "I coussd:\n",
            "Thave I be bfouo f Rullosim.\n",
            "Ys f hpr whertholyor lerwecre's howongr!\n",
            "Glf! alltore odn? ke y  he fu,\n",
            "Tth pus thiencouldntes ocld mer,\n",
            "Ye med INhig Pse\n",
            "ARewil\n"
          ]
        }
      ],
      "source": [
        "## Generate from the model .Not great .Not too bad either\n",
        "context=torch.zeros((1,1),dtype=torch.long,device=device)\n",
        "print(decode(m.generate(context,max_new_tokens=2000)[0].tolist()))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
